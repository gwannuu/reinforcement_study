\documentclass[8pt]{beamer}
\usefonttheme[onlymath]{serif}



\setbeamertemplate{frametitle}{%
  \vskip1ex
  \usebeamerfont{titlebig}%
  \insertsectionhead
  \usebeamerfont{framesubtitlefont}
  \!:\insertsubsectionhead
  \par        %  ← 원하는 대로 변경 가능
  \vskip1ex
  \hrule
}

\usepackage[
  backend=biber,
  style=authoryear,   % or numeric
  citestyle=authoryear
]{biblatex}
\addbibresource{../../references.bib}


% 테마 선택 (선택 사항)
% \usetheme{Madrid} % 기본 테마, 다른 테마 사용 가능
% \font{serif}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[T1]{fontenc} % To use combination of textbf, textit
\usepackage[dvipsnames]{xcolor}   % can use more variant colors

% \setcounter{MaxMatrixCols}{20}

% (필요한 패키지들)
% \usepackage{amsthm}
\setbeamertemplate{theorems}[numbered]  % 정리, 정의 등에 번호를 달아줌

% \theoremstyle{plain} % insert bellow all blocks you want in italic
% \newtheorem{theorem}{Theorem}[section] % to number according to section
% 
% \theoremstyle{definition} % insert bellow all blocks you want in normal text
% \newtheorem{definition}{Definition}[section] % to number according to section
% \newtheorem*{idea}{Proof idea} % no numbered block

\newtheorem{proposition}[theorem]{Proposition}

\usepackage{tcolorbox}

% 필요할 경우 패키지 추가
\usepackage{graphicx} % 이미지 삽입을 위한 패키지
\usepackage{amsmath}   % 수식 사용
\usepackage{hyperref}  % 하이퍼링크 추가
\usepackage{cleveref}
\usepackage{multicol}  % 여러 열 나누기
\usepackage{ulem} % 취소선 및줄 나누기



\newcommand{\mrm}[1]{\mathrm{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\tb}[1]{\textbf{#1}}
\newcommand{\ti}[1]{\textit{#1}}
\newcommand{\mypois}[1]{\operatorname{Pois}(#1)}

\newcommand{\myber}[1]{\operatorname{Bern}\!\left(#1\right)}
\newcommand{\mybin}[2]{\operatorname{Bin}\!\left(#1,#2\right)}
\newcommand{\mytoinf}[1]{#1 \rightarrow \infty}
\newcommand{\myexp}[1]{\exp{\left(#1\right)}}
\newcommand{\myunif}[2]{\operatorname{Unif}\!\left(#1, #2\right)}
\newcommand{\mygeom}[1]{\operatorname{Geom}\!\left(#1\right)}
\newcommand{\myexpo}[1]{\operatorname{Expo}\!\left(#1\right)}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\expec}[1]{\operatorname{E}\left[ #1 \right]}
\newcommand{\myvar}[1]{\operatorname{Var}\left[#1\right]}
\newcommand{\myskew}[1]{\operatorname{Skew}\!\left[#1\right]}
\newcommand{\mykurt}[1]{\operatorname{Kurt}\!\left[#1\right]}
\newcommand{\mywei}[2]{\operatorname{Wei}\!\left(#1, #2\right)}
\newcommand{\Span}[1]{\operatorname{Span}\!\left(#1\right)}
\newcommand{\argmax}[1]{\operatorname{arg max}_{#1}}
\newcommand{\argmin}[1]{\operatorname{arg min}_{#1}}
\newcommand{\nll}[1]{\operatorname{NLL}\!\left(#1\right)}
\newcommand{\rss}[1]{\operatorname{RSS}\!\left(#1\right)}

% 발표 제목, 저자, 날짜 설정
\title{DL Foundation}
\author{Gwanwoo Choi}
% \date{}

\begin{document}
% 표지 슬라이드
\begin{frame}
    \titlepage
\end{frame}


\section{Regularization}
\begingroup
    \setbeamertemplate{frametitle}{%
        \vskip1ex
        \usebeamerfont{frametitle}%
        \insertframetitle\par
        \vskip1ex
        \hrule
    }
    \begin{frame}
        \frametitle{Table of Content}
        \tableofcontents
    \end{frame}
\endgroup

\subsection{Weight Decay}
\begin{frame}{.}
    Weight decay prohibit that each parameter has too large value.
    In L2 regularization, By adding $\sum_i \theta_i^2$ to loss, regularizes each parameter value.
\end{frame}

\subsection{Batch Normalization}


\begin{frame}{.}
    %\cite{Understanding_Batch_Normalization_nips_2018}

    \begin{block}{Batch Normalization}
        For $4$-dimension input tensor, $I_{b,c,h,w}$ and $4$-dimension output tensor, $O_{b,c,h,w}$, Batch normalization layer is defined by
        \[
            O_{b,c,h,w} = \gamma_c \frac{I_{b,c,h,w} - \mu_c}{\sqrt{\sigma^2_c + \epsilon}} + \beta_c
        \]
        where $\mu_c = \frac{1}{\abs{BHW} } \sum_{b,h,w} I_{b,c,h,w}$, $\sigma_c = \frac{1}{\abs{BHW}} \sum_{b,h,w} (I_{b,c,h,w} - \mu_c)^2$ is calculated for each mini-batch. $\gamma_c$ and $\beta_c$ is trained parameter in BN layer.

        \smallskip
        Moving average mean and variance is updated by $\hat{\mu_c} \leftarrow (1-t)\mu_c + t\hat{\mu_c}$, $\hat{\sigma_c} \leftarrow (1-t) \sigma_c + t \hat{\sigma_c}$ and stored in training phase. These stored moving average statistics is used for applying inear transform in inference phase.
        \[
            O_{b,c,h,w} = \frac{\hat{\gamma_c}}{\sqrt{\hat{\sigma_c}^2}+ \epsilon} I_{b,c,h,w} + \left(\beta_c  - \frac{\hat{\gamma_c}}{\sqrt{\hat{\sigma^2} + \epsilon}}\hat{\mu_c}\right)
        \]
    \end{block}


    \footcite{Understanding_Batch_Normalization_nips_2018,ioffe2015batch}
\end{frame}

\begin{frame}{.}
    \begin{itemize}
        \item Batch Normalization enables higher learning rate.
        \item Generally, adapting Batch Normalization preceded before activation (e.g. ReLU) is preferred.
    \end{itemize}
\end{frame}

\subsection{Layer Normalization}

\begin{frame}{.}
    Layer Normalization similar normalization technique with batch normalizaition but instead applied to non-channel dimension, ($h,w$ in image domain and $d$ in language domain).
    \begin{itemize}
        \item Batch Normalization is dependent on mini-batch size. Extremely speaking, if batch size is $1$, then BN practically does not work well.
        \item Batch Normalization is ambiguous to apply in RNN
    \end{itemize}

    \begin{block}{Layer Normalization}
        For $4$-dimensional input $I_{b,c,h,w}$, $\mu_b = \frac{1}{\abs{C H W}}\sum_{c,h,w} I_{b,c,h,w}$ and $\sigma_b = \frac{1}{\abs{C H W}} \sum_{c,h,w} (I_{b,c,h,w} - \mu_b)^2$. Output $O_{b,c,h,w}$ is calculated by
        \[
            O_{b,c,h,w} = \gamma_b \frac{I_{b,c,h,w} - \mu_b}{\sqrt{\sigma_c^2 + \epsilon}} + \beta_b
        \]

        For $3$-dimensional input $I_{b,s,d}$, $\mu_b = \frac{1}{\abs{S D}}\sum_{s,d} I_{b,s,d}$ and $\sigma_b = \frac{1}{\abs{S D}} \sum_{s,d} (I_{b,s,d} - \mu_b)^2$. Output $O_{b,s,d}$ is calculated by
        \[
            O_{b,s,d} = \gamma_b \frac{I_{b,s,d} - \mu_b}{\sqrt{\sigma_b^2 + \epsilon}} + \beta_b
        \]
    \end{block}
\end{frame}


\section{Loss}

\begingroup
    \setbeamertemplate{frametitle}{%
        \vskip1ex
        \usebeamerfont{frametitle}%
        \insertframetitle\par
        \vskip1ex
        \hrule
    }%
    \begin{frame}
        \frametitle{Table of Content}
        \tableofcontents
    \end{frame}
\endgroup

\subsection{L1, L2 Loss}

\begin{frame}{.}
    If there exists function $f: \mbb{R}^d \to \mbb{R}$ with parameter $\theta$, then L1 and L2 loss of batch input $x_{b,d}$ and target $y_{b}$ is defined by
    \[
    L_1(x,y) = \frac{1}{\abs{B}}\sum_{b}\abs{f_\theta(x_{b,d}) - y_{b}}
    \]
    \[
    L_2(x,y) = \frac{1}{\abs{B}}\sum_{b} (f_\theta(x_{b,d}) - y_{b})^2
    \]

    \begin{itemize}
        \item L2 loss is efficient to get rid of outliers. L1 loss is relatively less efficient to remove outliers.
        \item L2 loss converges slower than L1 loss when $\abs{f_\theta(x_{b,d}) - y_b} < 1$
    \end{itemize}

    Huber loss is is defined by
    \[
        L(x,y)=\sum_b \frac{1}{\abs{B}}\begin{cases}
            \abs{f_\theta(x_{b,d}) - y_b} & \text{if } \abs{f_\theta(x_{b,d}) - y_b} > 1 \\
            (f_\theta(x_{b,d}) - y_b)^2 & \text{else} 
        \end{cases}
    \]
    \begin{itemize}
        \item Huber loss takes advantage of both methods and reduce disadvantages
    \end{itemize}
\end{frame}

\subsection{Cross Entropy Loss}

\begin{frame}{.}
    If there exists function $f$ with paramtere $\theta$, then cross entropy loss for category $C$, input $x_{b,d}$, target category $y_{b}$ is defined by
    \[
        L(x,y) = \frac{1}{\abs{B}} \sum_{c \in C, b} \mb{1}(c = y_b) \log{( \operatorname{Softmax}(f_\theta(x_{b, :}))_{c})}
    \]
    Where $\operatorname{Softmax}$ turns logits to probability distribution for categories $C$.
\end{frame}

\subsection{Contrastive Loss}

\begin{frame}{.}
    Object of contrastive learning: In embedding space, make datas from same category more closer and datas from different categories move away.

    \bigskip
    Suppose there exists two categories, $c_1, c_2$ and there exists dataset corresponding to each category, $\mc{D}_1, \mc{D}_2$.
\end{frame}



\section{Optimization}
\begingroup
    \setbeamertemplate{frametitle}{%
        \vskip1ex
        \usebeamerfont{frametitle}%
        \insertframetitle\par
        \vskip1ex
        \hrule
    }%
    \begin{frame}
        \frametitle{Table of Content}
        \tableofcontents
    \end{frame}
\endgroup
\subsection{SGD, Momentum}

\begin{frame}{.}
    Given mini-batch input tensor $x_{b,d}$, function $f_\theta$, target $y_b$ and loss function $L_\theta$, Stochastic Gradient Descent is defined by
    \[
        \theta \leftarrow \theta - \alpha \nabla_\theta L (\theta; x, y)
    \]
    where $\alpha$ is called learning rate and adjusted manually.

    \bigskip
    Momentum is defined by
    \[
    \begin{gathered}
        m \leftarrow \beta m + \alpha \nabla_\theta L(\theta;x,y) \\
        \theta \leftarrow \theta  - m
    \end{gathered}
    \]
    Where $\alpha$ is learning rate and $\beta$ is hyperparameter which determines how much velocity will be keep. $\alpha$ is usually set around to $0.9$.
    \begin{itemize}
        \item In momentum, previous velocity is keeped by moving average.
        \item Parameter update is occured with updated velocity.
        \item Momentum can reduce oscillation exists in SGD.
    \end{itemize}
\end{frame}

\subsection{Nestrov accelerated gradient}
\begin{frame}{.}
    Similar with Momentum but utilize gradient of one-step further.

    \[
    \begin{gathered}
        m \leftarrow \beta m + \alpha \nabla_\theta L(\theta - m) \\
        \theta \leftarrow \theta - m
    \end{gathered}
    \]

\end{frame}

\subsection{Adagrad}
\begin{frame}{.}
    \begin{itemize}
        \item Adagrad pin points that infrequently updated parameters should be updated with larger step size and frequently updated parameters should be updated with smaller step size.
        \item With this intuition, Adagrad adjusts different step-size per each parameters.
    \end{itemize}

    Let denote $i$-th parameter as $\theta_{i}$. In Adagrad, per each parameters $\theta_i$, keeps track the sum of squared gradient of $\theta_{i}$ in every time step, $g_{i, t} = \sum_t (\nabla_{\theta_{i,t}} L(\theta_{:, t}))^2 $.

    \[
        \begin{gathered}
            g_{i} \leftarrow g_{i} + (\nabla_{\theta_{i}} L(\theta))^2 \\
            \theta_i \leftarrow \theta_i - \frac{\alpha}{\sqrt{g_i + \epsilon}} \nabla_{\theta_i} L(\theta)
        \end{gathered}
    \]

    \begin{itemize}
        \item By scaling general learning rate $\alpha$ by $\frac{1}{\sqrt{g_i + \epsilon}}$, Adagrad updates infrequently updated parameters with more larger step and frequently updated parameters with more smaller step.
        \item But since $g_i$ only increases, learning rate becomes more smaller and smaller. At some point learning rate is infinitely small, update not occured practically.
    \end{itemize}
\end{frame}

\subsection{RMSprop}
\begin{frame}{.}
    RMSprop fix the drawback of Adagrad, in which update rate shrink. Instead of adding square of gradients, RMSprop calculates exponentially decaying average of squared of gradient.
    \[
        \begin{gathered}
            g_i \leftarrow \gamma g_i  + (1- \gamma) (\nabla_{\theta_i} L(\theta))^2 \\
            \theta \leftarrow \theta - \frac{\alpha}{\sqrt{g_i + \epsilon}} \nabla_{\theta_i} L(\theta)
        \end{gathered}
    \]

\end{frame}

\subsection{Adadelta}
\begin{frame}{.}
    Main idea of Adadelta is same with RMSprop, but Adadelta also consider the unit of update values.
    In RMSprop, unit of update vector is $\frac{L}{\theta}$. (Unit of $\frac{\alpha}{\sqrt{g_i + \epsilon}}$ is  $\frac{1}{\theta}$ and unit of $\nabla_{\theta_i} L(\theta)$ is $L$.)

    To match the scale of update term with parameters, it also track the difference of parameter $\Delta \theta^2$ by exponentially decaying average.

    \[
    \begin{gathered}
        g_{i,t} = \gamma g_{i,t-1} + (1- \gamma) (\nabla_{\theta_{i,t}} L(\theta_{:, t}))^2 \\
        \theta_{i,t+1} = -\frac{\sqrt{h_{i,t-1} + \epsilon}}{\sqrt{g_{i, t} + \epsilon}} \nabla_{\theta_{i,t}} L(\theta_{:,t}) \\
        h_{i,t} = \gamma h_{i,t-1} + (1-\gamma) (\theta_{i,t} - \theta_{i,t-1})^2 \\
    \end{gathered}
    \]

\end{frame}

\subsection{Adam}
\begin{frame}{.}
    Adam combines Momentum and RMSprop.
    \begin{itemize}
        \item Momentum estimates first moment, $\nabla_\theta L(\theta)$ by exponentially decaying average and RMSprop estimates second moment, $(\nabla_\theta L(\theta))^2$ by exponentially decaying average.
        \item Adam naming comes from Adaptive Moment Estimation.
        \item Adam updates recently infrequently updated parameters with more larger velocity and recently frequently updated parameters with smaller velocity.
        \item velocity is also keeped by exponentially decaying average, like in Momentum.
    \end{itemize}

    \[
    \begin{gathered}
        m \leftarrow \beta m + (1- \beta) \nabla_{\theta} L(\theta) \\
        g_i \leftarrow \gamma g_i  + (1- \gamma) (\nabla_{\theta_i} L(\theta))^2\\
        \theta_i \leftarrow \theta_i - \frac{\alpha}{\sqrt{g_i + \epsilon}} m
    \end{gathered}
    \]
\end{frame}

\begin{frame}{.}
    \begin{itemize}
        \item But in this setting, $m$ and $g$ are initialized by $0$. so in initial timesteps of training, $m$ and $g$ are biased to $0$.
        \item So this should be corrected. $\hat{m} = \frac{m}{1 - \beta^t}$ and $\hat{g} = \frac{g}{1 - \gamma^t}$.
        \item This fixed bias term $\hat{m}$ and $\hat{g}$ incrases $m$ and $g$ when time step $t$ is small, and as $t$ increases, $\hat{m} \rightarrow m$ and $\hat{g} \rightarrow g$.
    \end{itemize}

    \[
        \begin{gathered}
        m \leftarrow \beta m + (1- \beta) \nabla_{\theta} L(\theta) \\
        g_i \leftarrow \gamma g_i  + (1- \gamma) (\nabla_{\theta_i} L(\theta))^2\\
        \theta_i \leftarrow \theta_i - \frac{\alpha}{\sqrt{\hat{g}_i} + \epsilon}\hat{m}
    \end{gathered}
    \]

    Authors propose default value of $\beta, \gamma, \epsilon$ as $0.9, 0.999, 10^{-8}$
\end{frame}

\section{Architecture}
\begingroup
    \setbeamertemplate{frametitle}{%
        \vskip1ex
        \usebeamerfont{frametitle}%
        \insertframetitle\par
        \vskip1ex
        \hrule
    }%
    \begin{frame}
        \frametitle{Table of Content}
        \tableofcontents
    \end{frame}
\endgroup
\subsection{Transformer}


\subsection{Diffusion}

\begin{frame}{.}

\end{frame}

\end{document}